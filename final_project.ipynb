{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final_project.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJPbQl3kW5ba","executionInfo":{"status":"ok","timestamp":1619731817525,"user_tz":300,"elapsed":511,"user":{"displayName":"Seok Hwan Song","photoUrl":"","userId":"12221887087148431722"}},"outputId":"f0873468-ac94-4178-af6c-fdaa60b0276a"},"source":["%%writefile final_project.py\n","#!usr/bin/env python\n","import os\n","import sklearn as skl\n","from sklearn.model_selection import GridSearchCV, LeaveOneOut, cross_validate, cross_val_score, KFold, train_test_split\n","from sklearn.metrics import SCORERS\n","from sklearn import metrics\n"," \n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.svm import SVR\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn import preprocessing\n","\n","import numpy as np\n","from scipy.stats import pearsonr, spearmanr\n","import itertools\n","\n","# make sure the experiment can be replicated.\n","seed = 42\n","k10 = KFold(10, shuffle=True, random_state=seed)\n","\n","# download and load data\n","os.system('rm -f organic_chemistry_data.csv && wget https://raw.githubusercontent.com/forrestbao/MLClass/master/projects/organic_chemistry_data.csv')\n","\n","f = open('organic_chemistry_data.csv', 'rb')\n","data = np.loadtxt(f, delimiter=',', skiprows=1)\n","f.close()\n","\n","x = data[:, [2] + list(range(8, 12))]\n","y = data[:, 3: 8]\n","\n","# preprocess data\n","scaler = preprocessing.StandardScaler().fit(x)\n","X = scaler.transform(x)\n","\n","# split data to training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=seed)\n","print('Train size:', len(y_train), '; Test size:', len(y_test))\n","print('\\n')\n","\n","loo = LeaveOneOut()\n","\n","###################################################################\n","# 1. train the models and find the best hyperparameters for each model by 10-fold or leaveoneout cv.\n","###################################################################\n","print('1. train the models and find the best hyperparameters for each model by 10-fold or leaveoneout cv.')\n","# 1.1. SVR\n","clf_svr = MultiOutputRegressor(SVR())\n","param_svr = {\n","    'estimator__C': [10**elem for elem in range(-5, 5)],\n","    'estimator__gamma': [10**elem for elem in range(-5, 5)]\n","}\n","\n","gs_svr = (GridSearchCV(estimator=clf_svr, \n","                        param_grid=param_svr, \n","                        #cv=loo,\n","                        cv=KFold(10, shuffle=True, random_state=seed),\n","                        #scoring='neg_mean_squared_error',\n","                        scoring='r2',\n","                        n_jobs=-1))\n","\n","print('\\n1.1 SVR:')\n","print('\\nhyperparameters and their ranges:')\n","#print(param_svr)\n","for i, j in param_svr.items():\n","    print(i[11:] + ':', j)\n","\n","print('\\nthe best hyperparameters:')\n","#gs_svr.fit(X_train, y_train)\n","gs_svr.fit(X, y)\n","#print((gs_svr.predict(X_test) - y_test))\n","#print(gs_svr.best_params_)\n","for i, j in gs_svr.best_params_.items():\n","    print('best ' + i[11:] + ':', j)\n","\n","\n","# 1.2. Randomforest\n","clf_rf = MultiOutputRegressor(RandomForestRegressor())\n","param_rf = {\n","    'estimator__max_depth': [1, 2, 4, 8, 16, 32],\n","    'estimator__min_impurity_decrease': [0, 1e-10, 1e-5]\n","}\n","\n","gs_rf = (GridSearchCV(estimator=clf_rf, \n","                        param_grid=param_rf, \n","                        #cv=loo,\n","                        cv=KFold(10, shuffle=True, random_state=seed),\n","                        #scoring =['neg_mean_absolute_error', 'r2'],\n","                        #scoring='neg_mean_squared_error',\n","                        scoring='r2',\n","                        n_jobs=-1))\n","\n","print('\\n1.2 Random forest:')\n","print('\\nhyperparameters and their ranges:')\n","#print(param_rf)\n","for i, j in param_rf.items():\n","    print(i[11:] + ':', j)\n","\n","print('\\nthe best hyperparameters:')\n","#gs_rf.fit(X_train, y_train)\n","gs_rf.fit(X, y)\n","#print((gs_rf.predict(X_test) - y_test))\n","#print(gs_rf.best_params_)\n","for i, j in gs_rf.best_params_.items():\n","    print('best ' + i[11:] + ':', j)\n","\n","# 1.3. Nerual network\n","\n","# generate the layer and neuron parameters.\n","lyrs = []\n","for i in range(3):\n","    lyrs.extend(itertools.product([16, 24, 32], repeat=i+1))\n","\n","clf_nn = MultiOutputRegressor(MLPRegressor())\n","param_nn = {\n","    'estimator__hidden_layer_sizes': lyrs,\n","     'estimator__max_iter': [2, 8, 32, 128, 256],\n","     'estimator__alpha': [1e-5, 1e-3, 1e-1]\n","}\n","\n","gs_nn = (GridSearchCV(estimator=clf_nn, \n","                        param_grid=param_nn, \n","                        #cv=loo,\n","                        cv=KFold(10, shuffle=True, random_state=seed),\n","                        #scoring =['neg_mean_absolute_error', 'r2'],\n","                        #scoring='neg_mean_squared_error',\n","                        scoring='r2',\n","                        n_jobs=-1))\n","\n","print('\\n1.3 Neural Network:')\n","print('\\nhyperparameters and their ranges:')\n","#print(param_nn)\n","for i, j in param_nn.items():\n","    print(i[11:] + ':', j)\n","\n","print('\\nthe best hyperparameters:')\n","#gs_nn.fit(X_train, y_train)\n","gs_nn.fit(X, y)\n","#print((gs_nn.predict(X_test) - y_test))\n","#print(gs_nn.best_params_)\n","for i, j in gs_nn.best_params_.items():\n","    print('best ' + i[11:] + ':', j)\n","\n","\n","###################################################################\n","# 2. evaluate performance of different models with the best parameters\n","###################################################################\n","print('2. evaluate performance of different models with the best parameters')\n","\n","print('Method: The 10-fold cv with different score functions were used to evaluate the performance.')\n","print('              The mean and std of scores for train and test sets were reported.')\n","\n","# get the models with the best parameters\n","clf_best_svr = gs_svr.best_estimator_\n","clf_best_rf = gs_rf.best_estimator_\n","clf_best_nn = gs_nn.best_estimator_\n","\n","\n","# 2.1. RMSE\n","def rmse(y_p, y):\n","    return (((y_p - y) ** 2).mean())**.5\n","\n","rmse_sc = metrics.make_scorer(rmse, greater_is_better=False)\n","\n","print('\\n2.1 Performance by RMSE:')\n","\n","print('\\n2.1.1 SVR:')\n","svr_rmse_scores = cross_validate(clf_best_svr, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=rmse_sc, return_train_score=True)\n","svr_test_score = -svr_rmse_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(svr_test_score.mean(), svr_test_score.std()))\n","svr_train_score = -svr_rmse_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(svr_train_score.mean(), svr_train_score.std()))\n","\n","print('\\n2.1.2 Random forest:')\n","rf_rmse_scores = cross_validate(clf_best_rf, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=rmse_sc, return_train_score=True)\n","rf_test_score = -rf_rmse_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(rf_test_score.mean(), rf_test_score.std()))\n","rf_train_score = -rf_rmse_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(rf_train_score.mean(), rf_train_score.std()))\n","\n","print('\\n2.1.3 Neural network:')\n","nn_rmse_scores = cross_validate(clf_best_nn, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=rmse_sc, return_train_score=True)\n","nn_test_score = -nn_rmse_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(nn_test_score.mean(), nn_test_score.std()))\n","nn_train_score = -nn_rmse_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(nn_train_score.mean(), nn_train_score.std()))\n","\n","\n","# 2.2. Spearman's correlation coefficient\n","def scc(y_p, y):\n","    return spearmanr(y_p.flat, y.flat)[0]\n","\n","scc_sc = metrics.make_scorer(scc, greater_is_better=True)\n","\n","print('\\n2.2 Performance by Spearman correlation coefficient:')\n","\n","print('\\n2.2.1 SVR:')\n","svr_scc_scores = cross_validate(clf_best_svr, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=scc_sc, return_train_score=True)\n","svr_test_score = svr_scc_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(svr_test_score.mean(), svr_test_score.std()))\n","svr_train_score = svr_scc_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(svr_train_score.mean(), svr_train_score.std()))\n","\n","print('\\n2.2.2 Random forest:')\n","rf_scc_scores = cross_validate(clf_best_rf, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=scc_sc, return_train_score=True)\n","rf_test_score = rf_scc_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(rf_test_score.mean(), rf_test_score.std()))\n","rf_train_score = rf_scc_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(rf_train_score.mean(), rf_train_score.std()))\n","\n","print('\\n2.2.3 Neural network:')\n","nn_scc_scores = cross_validate(clf_best_nn, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=scc_sc, return_train_score=True)\n","nn_test_score = nn_scc_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(nn_test_score.mean(), nn_test_score.std()))\n","nn_train_score = nn_scc_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(nn_train_score.mean(), nn_train_score.std()))\n","\n","# 2.3. Pearson's correlation coefficient\n","print('\\n2.3 Performance by Pearson correlation coefficient:')\n","\n","def pcc(y_p, y):\n","    return pearsonr(y_p.flat, y.flat)[0]\n","\n","pcc_sc = metrics.make_scorer(pcc, greater_is_better=True)\n","\n","print('\\n2.3.1 SVR:')\n","svr_pcc_scores = cross_validate(clf_best_svr, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=pcc_sc, return_train_score=True)\n","svr_test_score = svr_pcc_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(svr_test_score.mean(), svr_test_score.std()))\n","svr_train_score = svr_pcc_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(svr_train_score.mean(), svr_train_score.std()))\n","\n","print('\\n2.3.2 Random forest:')\n","rf_pcc_scores = cross_validate(clf_best_rf, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=pcc_sc, return_train_score=True)\n","rf_test_score = rf_pcc_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(rf_test_score.mean(), rf_test_score.std()))\n","rf_train_score = rf_pcc_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(rf_train_score.mean(), rf_train_score.std()))\n","\n","print('\\n2.3.3 Neural network:')\n","nn_pcc_scores = cross_validate(clf_best_nn, X, y, cv=KFold(10, shuffle=True, random_state=seed), scoring=pcc_sc, return_train_score=True)\n","nn_test_score = nn_pcc_scores['test_score']\n","print('mean score (+/-sd) of test set: %s (+/-%s)'%(nn_test_score.mean(), nn_test_score.std()))\n","nn_train_score = nn_pcc_scores['train_score']\n","print('mean score (+/-sd) of train set: %s (+/-%s)'%(nn_train_score.mean(), nn_train_score.std()))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing final_project.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EhrFBuQpv8cs"},"source":["!python final_project.py > log_2.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7E9-G16nGmcQ"},"source":[""],"execution_count":null,"outputs":[]}]}